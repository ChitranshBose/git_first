{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f09c542-accc-4e44-a0ee-28fbec2c407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import time as t\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa89211-a806-4c65-94a2-b270a3325733",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=\"ASIAXYKJWW5VJDBY4OQI\"\n",
    "AWS_SECRET_ACCESS_KEY=\"Blnh6LJyPHwA5JgWP8m4X1ZFqgbca9v1lNd1vGiZ\"\n",
    "AWS_SESSION_TOKEN=\"IQoJb3JpZ2luX2VjEPv//////////wEaCXVzLWVhc3QtMSJIMEYCIQCXIhix2Bdx5HI6rm2PW5sOXBKbJ8ZTmuATbofA2k7SYAIhAPCOGiknTV4RBlbqO/Xuw7LZFbmSni0umkKIssJzTKvZKpsDCNT//////////wEQABoMNTMzMjY3Mzk2NDU4IgwJg0XoJU6h4BLnmAUq7wKstlaKqmRHnxdfL0p8sNhTIRV0JmHHR71Z79s7QnvlwzkWvLzkxlmLn+zXZp/KzI/PzH2fwPAAyzGTNqYFXZSqobqSw1xmsLIVn4OQhnU10fIgc1u46Jo2nQnXquVHW6emZ7YWEJ7lLFE7Vb5X6UFnC8I0sZY/pEQ/GPN2VxUPJywRSF61CC9wX7wcsm/ok6xBH4+uPeuR8cglb2JDcLiOTqsIB1eOabz+sDyKzhG8UPpFpFSkRurREUGlHyaWPMgSICTcm/fhqvbd6tEOtcJPqDzjo7/viOJM1rF7A34n6EVSemMT3V+8E0PL1eeeq+pZAYzRTltjT8Y+z73ccdeys6NtGBu/lgxVIlpTKUXYpZwrtmgMvExgYtVmly47gnN8R56CKpG6x+xXSZPXPb66KFksrJrOxcpm9muFok+WMzsapCBEXrKP5KOSEDOVMqyMvvH5laU5akDRqCG/dUzgFHP1IEJHRdoTxmlXHQSsMJaCjrUGOqUBxOq+IFzTGUyDaBSmlXbEQg6RR2T6TFPPqMN1tjO0xgxN2PpnTE5ErbVcjKWe2OXyCVQjqlONifY0wPuww+3FHNhR+jVJpOycU6XB72XPvB4vqUYvwDt+DJ5fT2spaK7kNNO2mdSQYanKY6Cy1dLdlPz/qxkNbZcNpiHcrfreA9kBN4+6ybsb6TUouhu+szQh+ZX3kBOGybVid83LfOhgvCvc3U9A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46765ea7-eae1-4d42-8703-af5f4d042d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = boto3.Session().get_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61b99ab4-9621-4bb6-b112-1f0d7ba6769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = AWS_ACCESS_KEY_ID\n",
    "secret_key = AWS_SECRET_ACCESS_KEY\n",
    "token = AWS_SESSION_TOKEN\n",
    "\n",
    "# access_key = cred.access_key\n",
    "# secret_key = cred.secret_key\n",
    "# token = cred.token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ced28c-2628-438a-b8c1-fa017bdbf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"vpc-autocoding-poc-bcsbo7jptehmmcbyw4v5gncy3a.us-east-1.es.amazonaws.com\"\n",
    "port = 443\n",
    "reg = \"us-east-1\"\n",
    "ser  = \"es\"\n",
    "session_kwargs = {\"region_name\":reg} \n",
    "client_kwargs = {**session_kwargs}\n",
    "client_kwargs[\"aws_access_key_id\"] = access_key\n",
    "client_kwargs[\"aws_secret_access_key\"] = secret_key\n",
    "client_kwargs[\"aws_session_token\"] = token  \n",
    "aws4Auth = AWS4Auth(access_key, secret_key, reg, ser, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fa40a62-e2d0-49b8-a95e-72397898ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenSearch(hosts = [{'host':host, \"port\": port}], http_auth = aws4Auth, use_ssl = True, verify_certs = True, connection_class = RequestsHttpConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62709330-f537-497e-adee-a444ab8e1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_body = {\n",
    "    'settings': {\n",
    "        'number_of_shards': 1,\n",
    "        'number_of_replicas': 0,\n",
    "        'index.knn': True,\n",
    "        'index.knn.space_type' : \"cosinesimil\"\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'English Reported': {'type': 'text',\"store\": True},\n",
    "            'English Coded LLT': {'type': 'text',\"store\": True},\n",
    "            'English Coded PT': {'type': 'text',\"store\": True},\n",
    "            'Count': {'type': 'integer', \"store\": True},\n",
    "            'Embeddings LLT': {\n",
    "                'type': 'knn_vector',\n",
    "                'dimension': 512,\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca4eb1-c0b6-4b9b-843d-d4751b437f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"test\"\n",
    "res = client.indices.create(index=index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3f5aaa-c973-45a7-b732-1b6035198b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.indices.get(index = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dc7d6-9c85-4e53-a039-30243d298cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(assumed_role = None, region = 'us-east-1', runtime = True, external_id = None, ep_url = None):\n",
    "    retry_config = Config(region_name = region, retries = {\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },)\n",
    "\n",
    "    sess = boto3.Session(**session_kwargs)\n",
    "    \n",
    "    service= 'bedrock-runtime'\n",
    "    bedrock_client = sess.client(service_name=service,config=retry_config, **client_kwargs )\n",
    "    return bedrock_client\n",
    "boto3_client = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91e100-3108-460a-9bce-06cc1a3e4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(data, model = \"amazon.titan-embed-text-v2:0\",region_name = 'us-east-1', dim = 512, norm = True):\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    body = json.dumps({\n",
    "            \"inputText\": data,\n",
    "            \"dimensions\": dim,\n",
    "            \"normalize\": norm\n",
    "        })\n",
    "    res = boto3_client.invoke_model(body = body, modelId = model, accept = accept, contentType = content_type)\n",
    "    res_body = json.loads(res.get('body').read())\n",
    "    return res_body['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96c972-b002-4346-a5c2-bb4cd8ca853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hybrid(term, k, vec, index, threshold = 80.0):\n",
    "    # implement 10 records filter\n",
    "    # query1 = {\n",
    "    #     \"size\": k,\n",
    "    #     \"query\":{\n",
    "    #         \"multi_match\":{\n",
    "    #             \"query\": term,\n",
    "    #             \"type\": \"phrase\",\n",
    "    #             \"fields\": ['English Reported']\n",
    "    #         }\n",
    "    #     }  \n",
    "    # }\n",
    "    # query_hybrid = {\n",
    "    #   \"size\": k,\n",
    "    #   \"query\": {\n",
    "    #     \"bool\": {\n",
    "    #       \"should\": [\n",
    "    #         {\n",
    "    #           \"match\": {\n",
    "    #             \"English Reported\": term\n",
    "    #           }\n",
    "    #         },\n",
    "    #         {\n",
    "    #           \"script_score\": {\n",
    "    #             \"query\": {\n",
    "    #               \"match_all\": {}\n",
    "    #             },\n",
    "    #             \"script\": {\n",
    "    #               \"source\": \"knn_score\",\n",
    "    #               \"lang\": \"knn\",\n",
    "    #               \"params\": {\n",
    "    #                 \"field\": \"Embeddings\",\n",
    "    #                 \"query_value\": vec,\n",
    "    #                 \"space_type\": \"cosinesimil\" \n",
    "    #                 # \"k\": k\n",
    "    #               }\n",
    "    #             }\n",
    "    #           }\n",
    "    #         }\n",
    "    #       ]\n",
    "    #     }\n",
    "    #   }\n",
    "    # }\n",
    "    query1 = {\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                   {\n",
    "                        \"multi_match\":{\n",
    "                        \"query\": term,\n",
    "                        \"type\": \"phrase\",\n",
    "                        \"fields\": ['English Reported']\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                      \"range\": {\n",
    "                        \"Count\": {\n",
    "                          \"gte\":2\n",
    "                        }\n",
    "                      }\n",
    "                    } \n",
    "                ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    \n",
    "    query2 = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"Embeddings LLT\":{\n",
    "                    \"vector\":vec,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ls_data = []\n",
    "    res = client.search(index = index, body = query1) \n",
    "    if res['hits']['total']['value'] == 0:\n",
    "        print(\"Switching to semantic\")\n",
    "        res = client.search(index = index, body = query2)\n",
    "    if res['hits']['total']['value'] == 0:\n",
    "        df_match_data_res = pd.DataFrame(ls_data, columns = [\"English Reported\",\"English Coded LLT\",\"English Coded PT\",\"Count\",\"Score\"])\n",
    "        return df_match_data_res   \n",
    "    hits = res.get('hits',{}).get('hits',[])\n",
    "    max_score = res['hits']['max_score']\n",
    "    for doc in hits:\n",
    "        row = {\"English Reported\": doc['_source']['English Reported'], \"English Coded LLT\": doc['_source']['English Coded LLT'], \"English Coded PT\": doc['_source']['English Coded PT'], \"Count\": doc['_source']['Count'], \"Score\": doc['_score']}\n",
    "        ls_data.append(row)\n",
    "    \n",
    "    df_match_data_res = pd.DataFrame(ls_data, columns = [\"English Reported\",\"English Coded LLT\",\"English Coded PT\",\"Count\",\"Score\"])\n",
    "    df_match_data_res = df_match_data_res.drop_duplicates(['English Coded PT'])   \n",
    "    df_match_data_res = df_match_data_res.astype({\"Score\":float})\n",
    "    df_match_data_res=df_match_data_res.nlargest(k,\"Score\")\n",
    "    df_match_data_res['Score'] = (df_match_data_res['Score']/max_score)*100\n",
    "    df_match_data_res['Score'] = df_match_data_res['Score'].apply(lambda x: float(x))\n",
    "    df_match_data_res.reset_index(inplace=True)\n",
    "    df_match_data_res.drop(['index'], inplace=True, axis=1)\n",
    "    df_match_data_res = df_match_data_res[df_match_data_res['Score']>threshold]\n",
    "    return df_match_data_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c45cd-7a52-4e4a-ad32-967d16bd9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kickback(data):\n",
    "    term = data['English Reported']\n",
    "    lt_code = data['English Coded LLT']\n",
    "    pt_code = data['English Coded PT']\n",
    "    cnt = data['Count']\n",
    "    query = {\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                    \"multi_match\":{\n",
    "                    \"query\": term,\n",
    "                    \"type\": \"phrase\",\n",
    "                    \"fields\": ['English Reported']\n",
    "                }\n",
    "                },\n",
    "                {\n",
    "                    \"multi_match\":{\n",
    "                    \"query\": lt_code,\n",
    "                    \"type\": \"phrase\",\n",
    "                    \"fields\": ['English Coded LLT']\n",
    "                    }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "    }\n",
    "\n",
    "    res = client.search(index = index, body = query)\n",
    "    hits = res.get('hits',{}).get('hits',[])  \n",
    "    if res['hits']['total']['value'] > 0:\n",
    "        print(\"Updating count\")\n",
    "        for doc in hits:\n",
    "            id = doc['_id']\n",
    "            count = doc['_source']['Count']\n",
    "            count+=cnt\n",
    "            document = {\"Count\": count}\n",
    "            body = {\"doc\": document}\n",
    "            res = client.update(index = index, id=id, body = body)\n",
    "            \n",
    "    else:\n",
    "        print(\"New index created\")\n",
    "        vec = embedding(term)\n",
    "        body = {\n",
    "            \"English Reported\" : term,\n",
    "            \"English Coded LLT\": lt_code,\n",
    "            \"English Coded PT\":  pt_code,\n",
    "            \"Count\": 1,\n",
    "            \"Embeddings LLT\": vec\n",
    "        }\n",
    "        res = client.index(index=index, body=body)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1a55b-825c-49c1-893e-99189278a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_terms = pd.read_excel('/home/chitranshbose/Downloads/Data for MedDRA AutoCoding_EL.xlsx', sheet_name='Terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fad40c-4a8b-40cb-bb4b-3d33b7729dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingest = data_terms[['English Reported', 'English Coded LLT','English Coded PT']].iloc[:900000,:]\n",
    "data_ingest = data_ingest.groupby(data_ingest.columns.tolist(), as_index=False).size()\n",
    "data_ingest.rename(columns = {\"size\":\"Count\"}, inplace = True)\n",
    "data_ingest['Embeddings LLT'] = data_ingest['English Coded LLT'].apply(embedding)\n",
    "data_ingest['English Reported'] = data_ingest['English Reported'].str.lower()\n",
    "data_ingest['English Coded LLT'] = data_ingest['English Coded LLT'].str.lower()\n",
    "data_ingest['English Coded PT'] = data_ingest['English Coded PT'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361244ee-cbf0-4962-a106-e8550668df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e923880-5b03-4fd7-88ae-8d331d8fd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in data_ingest.iterrows():\n",
    "    doc = row.to_dict()\n",
    "    client.index(index=index_name, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2de57-88c1-430f-b568-bade8d94f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.search(index=\"test\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c982f-ffeb-40d2-b09d-a6a207ff8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    text = \"faecal impaction\"\n",
    "    embds_query = embedding(text)\n",
    "    output1 = search_hybrid(text,10, embds_query, 'test') \n",
    "    '''this will return the LLT term and search will go medra'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf102c2-89dc-430c-9e0f-13000764af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing test data for kickback validation (test script)\n",
    "data_modify = data_terms[['English Reported', 'English Coded LLT','English Coded PT']].iloc[900000:,:]\n",
    "data_modify['English Reported'] = data_modify['English Reported'].str.lower()\n",
    "data_modify['English Coded LLT'] = data_modify['English Coded LLT'].str.lower()\n",
    "data_modify['English Coded PT'] = data_modify['English Coded PT'].str.lower()\n",
    "data_modify = data_modify.groupby(data_modify.columns.tolist(), as_index=False).size()\n",
    "data_modify.rename(columns = {\"size\":\"Count\"}, inplace = True)\n",
    "data_temp = data_injest.sample(frac = 0.4).drop(['Embeddings LLT'], axis=1)\n",
    "data_modify = pd.concat([data_modify, data_temp], axis=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb85ef-adb2-455a-a470-b5551fbc0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data.apply(kickback, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
